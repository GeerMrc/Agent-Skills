#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ€èƒ½æµ‹è¯•å·¥å…·

éªŒè¯SKILL.mdå®Œæ•´æ€§ã€æ–‡æ¡£å¯¼èˆªé“¾æ¥å’Œç»“æ„è§„èŒƒã€‚

ç”¨æ³•:
    python test-skill.py
    python test-skill.py --format json

ç¤ºä¾‹:
    python test-skill.py
    python test-skill.py --format markdown --output skill-test-report.md
"""

import sys
import argparse
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field


@dataclass
class TestIssue:
    """æµ‹è¯•é—®é¢˜"""
    level: str  # 'error', 'warning', 'info'
    category: str  # 'structure', 'navigation', 'content', 'format'
    location: str
    message: str
    suggestion: Optional[str] = None


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœ"""
    total_tests: int
    passed: int
    failed: int
    warnings: int
    issues: List[TestIssue] = field(default_factory=list)

    @property
    def is_valid(self) -> bool:
        return self.failed == 0


class SkillTester:
    """æŠ€èƒ½æµ‹è¯•å™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.skill_file = project_root / "SKILL.md"
        self.references_dir = project_root / "references"
        self.issues: List[TestIssue] = []

    def run_all_tests(self) -> TestResult:
        """
        è¿è¡Œæ‰€æœ‰æµ‹è¯•

        Returns:
            æµ‹è¯•ç»“æœ
        """
        self.issues = []
        tests = 0
        passed = 0

        # 1. æ£€æŸ¥SKILL.mdå­˜åœ¨
        tests += 1
        if self._test_skill_file_exists():
            passed += 1

        # 2. æ£€æŸ¥SKILL.mdè¡Œæ•°
        tests += 1
        if self._test_skill_line_count():
            passed += 1

        # 3. æ£€æŸ¥å¿…éœ€ç« èŠ‚
        tests += 1
        if self._test_required_sections():
            passed += 1

        # 4. æ£€æŸ¥æ–‡æ¡£å¯¼èˆª
        tests += 1
        if self._test_documentation_links():
            passed += 1

        # 5. æ£€æŸ¥referencesç›®å½•ç»“æ„
        tests += 1
        if self._test_references_structure():
            passed += 1

        # 6. æ£€æŸ¥æ–‡æ¡£è¡Œæ•°é™åˆ¶
        tests += 1
        if self._test_document_line_limits():
            passed += 1

        # 7. æ£€æŸ¥æ–‡æ¡£READMEæ–‡ä»¶
        tests += 1
        if self._test_readme_files():
            passed += 1

        # 8. æ£€æŸ¥ç¤ºä¾‹æ–‡æ¡£
        tests += 1
        if self._test_example_documents():
            passed += 1

        failed = sum(1 for i in self.issues if i.level == 'error')
        warnings = sum(1 for i in self.issues if i.level == 'warning')

        return TestResult(
            total_tests=tests,
            passed=passed,
            failed=failed,
            warnings=warnings,
            issues=self.issues
        )

    def _test_skill_file_exists(self) -> bool:
        """æ£€æŸ¥SKILL.mdå­˜åœ¨"""
        if not self.skill_file.exists():
            self.issues.append(TestIssue(
                level='error',
                category='structure',
                location='SKILL.md',
                message='SKILL.mdæ–‡ä»¶ä¸å­˜åœ¨',
                suggestion='åˆ›å»ºSKILL.mdä½œä¸ºæŠ€èƒ½å…¥å£ç‚¹'
            ))
            return False
        return True

    def _test_skill_line_count(self) -> bool:
        """æ£€æŸ¥SKILL.mdè¡Œæ•°"""
        if not self.skill_file.exists():
            return True

        lines = len(self.skill_file.read_text(encoding='utf-8').split('\n'))

        if lines > 200:
            self.issues.append(TestIssue(
                level='error',
                category='structure',
                location='SKILL.md',
                message=f'SKILL.mdè¡Œæ•°è¿‡å¤š: {lines}è¡Œ (è¦æ±‚â‰¤200è¡Œ)',
                suggestion='ä½¿ç”¨æ¸è¿›å¼æŠ«éœ²æ¶æ„ï¼Œå°†è¯¦ç»†å†…å®¹ç§»è‡³references/ç›®å½•'
            ))
            return False

        if lines > 180:
            self.issues.append(TestIssue(
                level='warning',
                category='structure',
                location='SKILL.md',
                message=f'SKILL.mdæ¥è¿‘è¡Œæ•°é™åˆ¶: {lines}è¡Œ',
                suggestion='è€ƒè™‘å°†éƒ¨åˆ†å†…å®¹ç§»è‡³references/ç›®å½•'
            ))

        return True

    def _test_required_sections(self) -> bool:
        """æ£€æŸ¥å¿…éœ€ç« èŠ‚"""
        if not self.skill_file.exists():
            return True

        content = self.skill_file.read_text(encoding='utf-8')
        required_sections = [
            '## ğŸ¯ æ ¸å¿ƒç†å¿µ',
            '## ğŸš€ å¿«é€Ÿå¼€å§‹',
            '## ğŸ“š æ–‡æ¡£å¯¼èˆª',
            '## ğŸ¨ å‰ç«¯ç¾å­¦æŒ‡å—',
            '## ğŸ”§ å·¥å…·ä¸è„šæœ¬',
        ]

        missing = []
        for section in required_sections:
            if section not in content:
                missing.append(section)

        if missing:
            for section in missing:
                self.issues.append(TestIssue(
                    level='error',
                    category='content',
                    location='SKILL.md',
                    message=f'ç¼ºå°‘å¿…éœ€ç« èŠ‚: {section}',
                    suggestion='æ·»åŠ è¯¥ç« èŠ‚åˆ°SKILL.md'
                ))
            return False

        return True

    def _test_documentation_links(self) -> bool:
        """æ£€æŸ¥æ–‡æ¡£å¯¼èˆªé“¾æ¥"""
        if not self.skill_file.exists():
            return True

        content = self.skill_file.read_text(encoding='utf-8')

        # æ£€æŸ¥referencesæ–‡æ¡£é“¾æ¥
        doc_links = re.findall(r'\[([^\]]+)\]\((references/[^)]+)\)', content)
        broken_links = []

        for title, link in doc_links:
            target_path = self.project_root / link
            if not target_path.exists():
                broken_links.append(f'{title} -> {link}')

        if broken_links:
            for link in broken_links:
                self.issues.append(TestIssue(
                    level='error',
                    category='navigation',
                    location='SKILL.md',
                    message=f'æ–‡æ¡£é“¾æ¥å¤±æ•ˆ: {link}',
                    suggestion='åˆ›å»ºç›®æ ‡æ–‡æ¡£æˆ–æ›´æ–°é“¾æ¥è·¯å¾„'
                ))
            return False

        return True

    def _test_references_structure(self) -> bool:
        """æ£€æŸ¥referencesç›®å½•ç»“æ„"""
        if not self.references_dir.exists():
            self.issues.append(TestIssue(
                level='error',
                category='structure',
                location='references/',
                message='referencesç›®å½•ä¸å­˜åœ¨',
                suggestion='åˆ›å»ºreferences/ç›®å½•å¹¶ç»„ç»‡æ–‡æ¡£'
            ))
            return False

        required_subdirs = [
            'methodology',
            'implementation',
            'aesthetics',
            'quality',
            'examples',
            'by-framework'
        ]

        missing = []
        for subdir in required_subdirs:
            if not (self.references_dir / subdir).exists():
                missing.append(subdir)

        if missing:
            for subdir in missing:
                self.issues.append(TestIssue(
                    level='warning',
                    category='structure',
                    location=f'references/{subdir}',
                    message=f'ç¼ºå°‘å­ç›®å½•: {subdir}',
                    suggestion=f'åˆ›å»ºreferences/{subdir}/ç›®å½•'
                ))

        return len(missing) == 0

    def _test_document_line_limits(self) -> bool:
        """æ£€æŸ¥æ–‡æ¡£è¡Œæ•°é™åˆ¶"""
        if not self.references_dir.exists():
            return True

        issues_found = False

        for doc_file in self.references_dir.rglob('*.md'):
            if doc_file.name == 'README.md':
                max_lines = 200  # READMEå…è®¸200è¡Œ
            else:
                max_lines = 400  # å…¶ä»–æ–‡æ¡£å…è®¸400è¡Œ

            lines = len(doc_file.read_text(encoding='utf-8').split('\n'))

            if lines > max_lines:
                self.issues.append(TestIssue(
                    level='warning',
                    category='content',
                    location=str(doc_file.relative_to(self.project_root)),
                    message=f'æ–‡æ¡£è¡Œæ•°è¿‡å¤š: {lines}è¡Œ (å»ºè®®â‰¤{max_lines}è¡Œ)',
                    suggestion='æ‹†åˆ†æ–‡æ¡£æˆ–ä½¿ç”¨æ¸è¿›å¼æŠ«éœ²æ¶æ„'
                ))
                issues_found = True

        return not issues_found

    def _test_readme_files(self) -> bool:
        """æ£€æŸ¥READMEæ–‡ä»¶"""
        if not self.references_dir.exists():
            return True

        missing_readme = []

        # æ£€æŸ¥å„å­ç›®å½•çš„README
        for subdir in ['methodology', 'implementation', 'aesthetics', 'quality', 'by-framework']:
            readme_path = self.references_dir / subdir / 'README.md'
            if not readme_path.exists():
                missing_readme.append(f'references/{subdir}/README.md')

        if missing_readme:
            for readme in missing_readme:
                self.issues.append(TestIssue(
                    level='info',
                    category='structure',
                    location=readme,
                    message='ç¼ºå°‘README.mdå¯¼èˆªæ–‡ä»¶',
                    suggestion='åˆ›å»ºREADME.mdæä¾›è¯¥ç›®å½•çš„æ–‡æ¡£å¯¼èˆª'
                ))

        return len(missing_readme) == 0

    def _test_example_documents(self) -> bool:
        """æ£€æŸ¥ç¤ºä¾‹æ–‡æ¡£"""
        examples_dir = self.references_dir / 'examples'

        if not examples_dir.exists():
            self.issues.append(TestIssue(
                level='info',
                category='content',
                location='references/examples/',
                message='examplesç›®å½•ä¸å­˜åœ¨',
                suggestion='åˆ›å»ºexamples/ç›®å½•å¹¶æ·»åŠ ç¤ºä¾‹æ–‡æ¡£'
            ))
            return False

        required_examples = [
            'component-examples.md',
            'layout-examples.md',
            'animation-examples.md'
        ]

        missing = []
        for example in required_examples:
            if not (examples_dir / example).exists():
                missing.append(example)

        if missing:
            for example in missing:
                self.issues.append(TestIssue(
                    level='info',
                    category='content',
                    location=f'references/examples/{example}',
                    message=f'ç¼ºå°‘ç¤ºä¾‹æ–‡æ¡£: {example}',
                    suggestion='åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ä»¥å¸®åŠ©ç”¨æˆ·ç†è§£æœ€ä½³å®è·µ'
                ))

        return len(missing) == 0


def format_report(result: TestResult, output_format: str = 'text') -> str:
    """æ ¼å¼åŒ–æŠ¥å‘Š"""
    if output_format == 'json':
        import json
        return json.dumps({
            'is_valid': result.is_valid,
            'total_tests': result.total_tests,
            'passed': result.passed,
            'failed': result.failed,
            'warnings': result.warnings,
            'issues': [
                {
                    'level': i.level,
                    'category': i.category,
                    'location': i.location,
                    'message': i.message,
                    'suggestion': i.suggestion
                }
                for i in result.issues
            ]
        }, ensure_ascii=False, indent=2)

    elif output_format == 'markdown':
        lines = [
            "# æŠ€èƒ½æµ‹è¯•æŠ¥å‘Š\n",
            f"**çŠ¶æ€**: {'âœ… é€šè¿‡' if result.is_valid else 'âŒ å¤±è´¥'}",
            f"**æµ‹è¯•**: {result.passed}/{result.total_tests} é€šè¿‡",
            f"**å¤±è´¥**: {result.failed}",
            f"**è­¦å‘Š**: {result.warnings}\n"
        ]

        if result.issues:
            lines.append("## é—®é¢˜åˆ—è¡¨\n")

            # æŒ‰ç±»åˆ«åˆ†ç»„
            by_category: Dict[str, List[TestIssue]] = {}
            for issue in result.issues:
                by_category.setdefault(issue.category, []).append(issue)

            for category, issues in by_category.items():
                lines.append(f"### {category.title()}\n")
                for issue in issues:
                    emoji = {'error': 'âŒ', 'warning': 'âš ï¸', 'info': 'â„¹ï¸'}.get(issue.level, 'âšª')
                    lines.append(f"#### {emoji} `{issue.location}`")
                    lines.append(f"{issue.message}")
                    if issue.suggestion:
                        lines.append(f"**å»ºè®®**: {issue.suggestion}")
                    lines.append("")

        return "\n".join(lines)

    else:  # text
        lines = [
            "=" * 60,
            "æŠ€èƒ½æµ‹è¯•æŠ¥å‘Š",
            "=" * 60,
            f"çŠ¶æ€: {'âœ… é€šè¿‡' if result.is_valid else 'âŒ å¤±è´¥'}",
            f"æµ‹è¯•: {result.passed}/{result.total_tests} é€šè¿‡",
            f"å¤±è´¥: {result.failed}",
            f"è­¦å‘Š: {result.warnings}",
            ""
        ]

        if result.issues:
            lines.append("é—®é¢˜åˆ—è¡¨:")
            lines.append("-" * 40)

            by_category: Dict[str, List[TestIssue]] = {}
            for issue in result.issues:
                by_category.setdefault(issue.category, []).append(issue)

            for category, issues in by_category.items():
                lines.append(f"\nã€{category.upper()}ã€‘")
                for issue in issues:
                    emoji = {'error': 'âŒ', 'warning': 'âš ï¸', 'info': 'â„¹ï¸'}.get(issue.level, 'âšª')
                    lines.append(f"\n{emoji} [{issue.level.upper()}] {issue.location}")
                    lines.append(f"    {issue.message}")
                    if issue.suggestion:
                        lines.append(f"    ğŸ’¡ {issue.suggestion}")

        lines.append("\n" + "=" * 60)
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='éªŒè¯Frontend Design Agent Skillså®Œæ•´æ€§',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--project-root', type=Path, default=Path.cwd(), help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--format', '-f', choices=['text', 'json', 'markdown'], default='text')
    parser.add_argument('--output', '-o', type=Path, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    tester = SkillTester(args.project_root)
    result = tester.run_all_tests()

    report = format_report(result, args.format)

    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(report)

    # æ‘˜è¦
    status = "âœ… é€šè¿‡" if result.is_valid else "âŒ å¤±è´¥"
    print(f"\nğŸ§ª æŠ€èƒ½æµ‹è¯• - {status}")
    print(f"   æµ‹è¯•: {result.passed}/{result.total_tests} | "
          f"å¤±è´¥: {result.failed} | è­¦å‘Š: {result.warnings}")

    return 0 if result.is_valid else 1


if __name__ == '__main__':
    sys.exit(main())
